{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icl57enwh0pg"
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRpuXgcxh7_g"
   },
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "t--29SwW0Q3y"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.nn.modules.activation import ReLU\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import ImageDataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNyaTU9HiAKN"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jw902nSd0PUt"
   },
   "outputs": [],
   "source": [
    "ImageDataModule = _temp.dataset.ImageDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Kmt4HoXf0YdD"
   },
   "outputs": [],
   "source": [
    "loader = ImageDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lisru4gS2GNQ",
    "outputId": "3df10e2e-f0ce-4a57-a433-ed629124c8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded samples into dataset with label 'no'=0 and 'yes'=1\n"
     ]
    }
   ],
   "source": [
    "loader.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CD97mCn5ihBD"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cilo_avii2zB"
   },
   "source": [
    "## 1. Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KxGSZH7Ci2lX"
   },
   "outputs": [],
   "source": [
    "EPOCH_NUMBER = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kI234lZDiDid"
   },
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BZGC8fTeCC0A"
   },
   "outputs": [],
   "source": [
    "def findnn(D1, D2):\n",
    "    \"\"\"\n",
    "    :param D1: NxD matrix containing N feature vectors of dim. D\n",
    "    :param D2: MxD matrix containing M feature vectors of dim. D\n",
    "    :return:\n",
    "        Idx: N-dim. vector containing for each feature vector in D1 the index of the closest feature vector in D2.\n",
    "        Dist: N-dim. vector containing for each feature vector in D1 the distance to the closest feature vector in D2\n",
    "    \"\"\"\n",
    "    N = D1.shape[0]\n",
    "    M = D2.shape[0]  # [k]\n",
    "\n",
    "    # Find for each feature vector in D1 the nearest neighbor in D2\n",
    "    Idx, Dist = [], []\n",
    "    for i in range(N):\n",
    "        minidx = 0\n",
    "        mindist = np.linalg.norm(D1[i, :] - D2[0, :])\n",
    "        for j in range(1, M):\n",
    "            d = np.linalg.norm(D1[i, :] - D2[j, :])\n",
    "\n",
    "            if d < mindist:\n",
    "                mindist = d\n",
    "                minidx = j\n",
    "        Idx.append(minidx)\n",
    "        Dist.append(mindist)\n",
    "    return Idx, Dist\n",
    "\n",
    "class Sobel(nn.Module):\n",
    "    # Sourced from https://github.com/chaddy1004/sobel-operator-pytorch/blob/master/model.py\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.filter = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=1, stride=1, padding='same', bias=False)\n",
    "\n",
    "        Gx = torch.tensor([[2.0, 0.0, -2.0], [4.0, 0.0, -4.0], [2.0, 0.0, -2.0]])\n",
    "        Gy = torch.tensor([[2.0, 4.0, 2.0], [0.0, 0.0, 0.0], [-2.0, -4.0, -2.0]])\n",
    "        G = torch.cat([Gx.unsqueeze(0), Gy.unsqueeze(0)], 0)\n",
    "        G = G.unsqueeze(1)\n",
    "\n",
    "        self.filter.weight = nn.Parameter(G, requires_grad=False)\n",
    "\n",
    "    def forward(self, img):\n",
    "        #Note there is a Gx and Gy on this\n",
    "        x = self.filter(img)\n",
    "        ''' \n",
    "        x = torch.mul(x, x)\n",
    "        x = torch.sum(x, dim=1, keepdim=True)\n",
    "        x = torch.sqrt(x) '''\n",
    "        return x\n",
    "\n",
    "\n",
    "def grid_points(img, nPointsX, nPointsY, border):\n",
    "    \"\"\"\n",
    "    :param img: input gray img, numpy array, [h, w]\n",
    "    :param nPointsX: number of grids in x dimension\n",
    "    :param nPointsY: number of grids in y dimension\n",
    "    :param border: leave border pixels in each image dimension\n",
    "    :return: vPoints: 2D grid point coordinates, numpy array, [nPointsX*nPointsY, 2]\n",
    "    \"\"\"\n",
    "    vPoints = None  # numpy array, [nPointsX*nPointsY, 2]\n",
    "\n",
    "    vPoints = np.zeros((nPointsX * nPointsY, 2))\n",
    "    \n",
    "    w, h = img.shape\n",
    "\n",
    "\n",
    "    # Are these integers? Should we make x Points integers\n",
    "    mult_x = (w - border - 1) / nPointsX\n",
    "\n",
    "    mult_y = (h - border - 1) / nPointsY\n",
    "\n",
    "    xPoints = [int(i * mult_x + 8) for i in range(nPointsX)]\n",
    "    yPoints = [int(i * mult_y + 8) for i in range(nPointsY)]\n",
    "    # Wrap around i*mult_x + 8 the term int\n",
    "\n",
    "    counter_g = 0\n",
    "    for x in xPoints:\n",
    "        for y in yPoints:\n",
    "            vPoints[counter_g][0] = x\n",
    "            vPoints[counter_g][1] = y\n",
    "            counter_g += 1\n",
    "\n",
    "    return vPoints\n",
    "\n",
    "\n",
    "def descriptors_hog(img, vPoints, cellWidth, cellHeight):\n",
    "    nBins = 8\n",
    "    w = cellWidth\n",
    "    h = cellHeight\n",
    "    \n",
    "    # to calculate the derivatives from an image\n",
    "    \n",
    "    grad_x, grad_y = Sobel()(img.view(-1, 128,128))\n",
    "\n",
    "    # What is cv2.CV_16S? a numerical type in CV\n",
    "\n",
    "    # tan^-1(dy  / dx)\n",
    "    orientation = np.arctan2(grad_x, grad_y) * 180 / np.pi\n",
    "\n",
    "    _, bin_edges_orientation = np.histogram(orientation, bins=nBins)\n",
    "    # bin_edges_orientation = np.array([i * 45 for i in range(9)])\n",
    "\n",
    "    descriptors = (\n",
    "        []\n",
    "    )  # list of descriptors for the current image, each entry is one 128-d vector for a grid point\n",
    "\n",
    "    for point in vPoints:\n",
    "        # nPointsX * nPointsY\n",
    "        point_descriptor = []\n",
    "        for pixel_x in range(w):\n",
    "            # 4 width\n",
    "            for pixel_y in range(h):\n",
    "                # 4 height\n",
    "                x_coord = int(point[0] - 2 + pixel_x)\n",
    "                y_coord = int(point[1] - 2 + pixel_y)\n",
    "\n",
    "                selection = orientation[x_coord, y_coord]\n",
    "                # 8 for histogram size of 8 bins\n",
    "                histogram, _ = np.histogram(selection, bins=bin_edges_orientation)\n",
    "                point_descriptor += [histogram]\n",
    "\n",
    "        descriptors += [point_descriptor]\n",
    "\n",
    "    descriptors = np.asarray(\n",
    "        descriptors\n",
    "    )  # [nPointsX*nPointsY, 128], descriptor for the current image (100 grid points)\n",
    "\n",
    "    # Checking that we do have the right shape\n",
    "    descriptors = np.reshape(descriptors, (vPoints.shape[0], 128))\n",
    "\n",
    "    # CLEARED FOR DEBUGGING\n",
    "    return descriptors\n",
    "\n",
    "\n",
    "def create_codebook(k, iterations):\n",
    "    \"\"\"\n",
    "    :param nameDirPos: dir to positive training images\n",
    "    :param nameDirNeg: dir to negative training images\n",
    "    :param k: number of kmeans cluster centers\n",
    "    :param iterations: maximum iteration numbers for kmeans clustering\n",
    "    :return: vCenters: center of kmeans clusters, numpy array, [k, 128]\n",
    "    \"\"\"\n",
    "    \n",
    "    cellWidth = 4\n",
    "    cellHeight = 4\n",
    "    nPointsX = 10\n",
    "    nPointsY = 10\n",
    "    border = 8\n",
    "\n",
    "    vFeatures = []\n",
    "    # list for all features of all images (each feature: 128-d, 16 histograms containing 8 bins)\n",
    "    # Extract features for all image\n",
    "    for batch in loader.train_dataloader():\n",
    "        batch = batch[0]\n",
    "        grey_batch = batch.mean(axis=1)\n",
    "        \n",
    "        for img in grey_batch:\n",
    "          vPoints = grid_points(img, nPointsX, nPointsY, border)\n",
    "          descriptors = descriptors_hog(img, vPoints, cellWidth, cellHeight)\n",
    "          vFeatures += [descriptors]\n",
    "\n",
    "    vFeatures = np.asarray(vFeatures)  # [n_imgs, n_vPoints, 128]\n",
    "    vFeatures = vFeatures.reshape(-1, vFeatures.shape[-1])  #[n_imgs*n_vPoints, 128]\n",
    "    print(\"number of extracted features: \", len(vFeatures))\n",
    "\n",
    "    # Cluster the features using K-Means\n",
    "    print(\"clustering ...\")\n",
    "    kmeans_res = KMeans(n_clusters=k, max_iter=iterations).fit(vFeatures)\n",
    "    vCenters = kmeans_res.cluster_centers_  # [k, 128]\n",
    "\n",
    "    return vCenters\n",
    "\n",
    "\n",
    "def bow_histogram(vFeatures, vCenters):\n",
    "    \"\"\"\n",
    "    :param vFeatures: MxD matrix containing M feature vectors of dim. D\n",
    "    :param vCenters: NxD matrix containing N cluster centers of dim. D\n",
    "    :return: histo: N-dim. numpy vector containing the resulting BoW activation histogram.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO\n",
    "\n",
    "    histo = np.zeros(vCenters.shape[0])\n",
    "    for descriptor in vFeatures:\n",
    "        dist = np.linalg.norm(vCenters - descriptor, axis=1)\n",
    "        chosen_cluster_center = np.argmin(dist)\n",
    "        histo[chosen_cluster_center] += 1\n",
    "\n",
    "    # Return a histogram based on the cluster centers\n",
    "    # Error was in labeling np.linalg norm with axis = 0 instea of 1\n",
    "    return histo\n",
    "\n",
    "\n",
    "def create_bow_histograms(label, vCenters, loader):\n",
    "    \"\"\"\n",
    "    :param label: dir of input images\n",
    "    :param vCenters: kmeans cluster centers, [k, 128] (k is the number of cluster centers)\n",
    "    :return: vBoW: matrix, [n_imgs, k]\n",
    "    \"\"\"\n",
    "\n",
    "    cellWidth = 4\n",
    "    cellHeight = 4\n",
    "    nPointsX = 10\n",
    "    nPointsY = 10\n",
    "    border = 8\n",
    "\n",
    "    # Extract features for all images in the given directory\n",
    "    vBoW = []\n",
    "    for batch in loader:\n",
    "        \n",
    "        # print('processing image {} ...'.format(i + 1))\n",
    "        for i in range(batch[1].shape[0]):\n",
    "          \n",
    "          img_label = batch[1][i]\n",
    "          if img_label != label: continue\n",
    "          img = batch[0][i]\n",
    "    \n",
    "          img = img.mean(axis=0) # [h, w]\n",
    "\n",
    "          vPoints = grid_points(img, nPointsX, nPointsY, border)\n",
    "          descriptors = descriptors_hog(img, vPoints, cellWidth, cellHeight)\n",
    "          # Adding to the histogram\n",
    "\n",
    "          vBoW += [bow_histogram(descriptors, vCenters)]\n",
    "\n",
    "    vBoW = np.asarray(vBoW)  # [n_imgs, k]\n",
    "\n",
    "    return vBoW\n",
    "\n",
    "\n",
    "def bow_recognition_nearest(histogram, vBoWPos, vBoWNeg):\n",
    "    \"\"\"\n",
    "    :param histogram: bag-of-words histogram of a test image, [1, k]\n",
    "    :param vBoWPos: bag-of-words histograms of positive training images, [n_imgs, k]\n",
    "    :param vBoWNeg: bag-of-words histograms of negative training images, [n_imgs, k]\n",
    "    :return: sLabel: predicted result of the test image, 0(without car)/1(with car)\n",
    "    \"\"\"\n",
    "\n",
    "    DistPos, DistNeg = None, None\n",
    "\n",
    "    # Find the nearest neighbor in the positive and negative sets and decide based on this neighbor\n",
    "\n",
    "    # It shows that all elements in negative have 100, 0,0,0,0,0,0,0 Histograms\n",
    "    \"\"\" DistNeg = np.argmin(np.linalg.norm(vBoWNeg - histogram))\n",
    "    print('Item with the smallest distance', vBoWNeg[DistNeg])\n",
    "    print('Histogram', histogram)\n",
    "    print('Rest of items in set', DistNeg) \"\"\"\n",
    "\n",
    "    DistNeg = np.min(np.linalg.norm(vBoWNeg - histogram, axis=1))\n",
    "\n",
    "    DistPos = np.min(np.linalg.norm(vBoWPos - histogram, axis=1))\n",
    "\n",
    "    if DistPos < DistNeg:\n",
    "        sLabel = 1\n",
    "    else:\n",
    "        sLabel = 0\n",
    "    return sLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J37ZA63vc6OH",
    "outputId": "10ec6e0a-2d63-4fbf-d380-85e403ff7fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating codebook ...\n",
      "number of extracted features:  22200\n",
      "clustering ...\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "k = 20\n",
    "iterations = 99\n",
    "print(\"creating codebook ...\")\n",
    "vCenters = create_codebook(k, iterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WhHnsqoSm2xh",
    "outputId": "3d83f1dc-ef5c-49c8-8c23-484139d39550"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating bow histograms (pos) ...\n",
      "creating bow histograms (neg) ...\n",
      "creating bow histograms for test set (pos) ...\n",
      "testing pos samples ...\n",
      "test pos sample accuracy: 0.875\n",
      "creating bow histograms for test set (neg) ...\n",
      "testing neg samples ...\n",
      "test neg sample accuracy: 1.0\n",
      "Overall accuracy: 0.9285714285714286\n"
     ]
    }
   ],
   "source": [
    "print(\"creating bow histograms (pos) ...\")\n",
    "vBoWPos = create_bow_histograms(1, vCenters, loader.train_dataloader())\n",
    "print(\"creating bow histograms (neg) ...\")\n",
    "vBoWNeg = create_bow_histograms(0, vCenters, loader.train_dataloader())\n",
    "\n",
    "# test pos samples\n",
    "print(\"creating bow histograms for test set (pos) ...\")\n",
    "vBoWPos_test = create_bow_histograms(1, vCenters, loader.test_dataloader())  # [n_imgs, k]\n",
    "result_pos = 0\n",
    "\n",
    "print(\"testing pos samples ...\")\n",
    "for i in range(vBoWPos_test.shape[0]):\n",
    "    cur_label_pos = bow_recognition_nearest(vBoWPos_test[i : (i + 1)], vBoWPos, vBoWNeg)\n",
    "    result_pos = result_pos + cur_label_pos\n",
    "acc_pos = result_pos / vBoWPos_test.shape[0]\n",
    "print(\"test pos sample accuracy:\", acc_pos)\n",
    "\n",
    "# test neg samples\n",
    "print(\"creating bow histograms for test set (neg) ...\")\n",
    "vBoWNeg_test = create_bow_histograms(0, vCenters, loader.test_dataloader())  # [n_imgs, k]\n",
    "\n",
    "result_neg = 0\n",
    "print(\"testing neg samples ...\")\n",
    "for i in range(vBoWNeg_test.shape[0]):\n",
    "    cur_label_neg = bow_recognition_nearest(vBoWNeg_test[i : (i + 1)], vBoWPos, vBoWNeg)\n",
    "    result_neg = result_neg + cur_label_neg\n",
    "acc_neg = 1 - result_neg / vBoWNeg_test.shape[0]\n",
    "print(\"test neg sample accuracy:\", acc_neg)\n",
    "\n",
    "overall_accuracy = ((acc_neg *vBoWNeg_test.shape[0]) + (acc_pos * vBoWPos_test.shape[0])) / (vBoWPos_test.shape[0] + vBoWNeg_test.shape[0])\n",
    "print(f\"Overall accuracy: {overall_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VSNv_204tcF8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [
    "icl57enwh0pg",
    "gheP09Zsh4V7",
    "YRpuXgcxh7_g",
    "cilo_avii2zB"
   ],
   "machine_shape": "hm",
   "name": "assignment_3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
