{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "from torchvision import models, transforms\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchmetrics import Accuracy\n",
    "import numpy as np\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Inspect dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"../data/images\", batch_size=32, num_workers=4, transform=None, normalize=False, shuffle=True):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transform = transform\n",
    "        self.data_dir = data_dir\n",
    "        self.normalize = normalize\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        # Define data transform\n",
    "        train_transform = []\n",
    "        if self.transform is not None:\n",
    "            train_transform+=self.transform\n",
    "        train_transform += [\n",
    "                transforms.Resize(224),             # resize shortest side to 128 pixels\n",
    "                transforms.CenterCrop(224),         # crop longest side to 128 pixels at center\n",
    "                transforms.ToTensor()               # convert PIL image to tensor\n",
    "        ]\n",
    "        test_transform = [\n",
    "                transforms.Resize(224),             # resize shortest side to 128 pixels\n",
    "                transforms.CenterCrop(224),         # crop longest side to 128 pixels at center\n",
    "                transforms.ToTensor()               # convert PIL image to tensor\n",
    "        ]\n",
    "\n",
    "        if self.normalize:\n",
    "            normalize_fn = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            train_transform.append(normalize_fn)\n",
    "            test_transform.append(normalize_fn)\n",
    "\n",
    "        train_transform = transforms.Compose(train_transform)\n",
    "        test_transform = transforms.Compose(test_transform)\n",
    "        \n",
    "        # Initialize train/test sets\n",
    "        train_dataset = ImageFolder(self.data_dir, transform=train_transform)\n",
    "        test_dataset = ImageFolder(self.data_dir, transform=test_transform)\n",
    "        classes = train_dataset.find_classes(self.data_dir)[1]\n",
    "        print(f\"Loaded samples into dataset with label 'no'={classes['no']} and 'yes'={classes['yes']}\")\n",
    "        \n",
    "        # Split dataset into train/test sets and stratify over labels to balance datasets with set seed \n",
    "        # DO NOT CHANGE THE SEED\n",
    "        generator = torch.Generator().manual_seed(390397)\n",
    "        train_len = int(0.8*len(train_dataset))\n",
    "        test_len = int((len(train_dataset)-train_len)/2)\n",
    "        train_dataset = random_split(\n",
    "            dataset=train_dataset, \n",
    "            lengths=[train_len, test_len, test_len],\n",
    "            generator=generator)[0]\n",
    "        val_dataset, test_dataset = random_split(\n",
    "            dataset=test_dataset, \n",
    "            lengths=[train_len, test_len, test_len],\n",
    "            generator=generator)[1:]\n",
    "        \n",
    "        self.train_dataset = train_dataset\n",
    "        self.val_dataset = val_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=self.shuffle)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ImageDataModule()\n",
    "dm.setup()\n",
    "images, labels = next(iter(dm.train_dataloader()))\n",
    "plt.imshow(images[30].permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBaseline(pl.LightningModule):\n",
    "    def __init__(self, lr=0.001):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False), # 64x64\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1, bias=False), # 32x32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1, bias=False), # 16x16\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False), # 8x8\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False), # 4x4\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1, bias=False), # 2x2\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 64, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "        self.optimizer = torch.optim.Adam\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_acc = Accuracy()\n",
    "        self.val_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.train_acc(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.val_acc(y_pred, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.test_acc(y_pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), lr=self.lr)\n",
    "        return optimizer\n",
    "\n",
    "class CNNTransferLearning(pl.LightningModule):\n",
    "    def __init__(self, lr=0.001, use_pretrained=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lr = lr\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        base_model = models.resnet18(pretrained=use_pretrained)\n",
    "        in_features = base_model.fc.in_features\n",
    "        layers = list(base_model.children())[:-1]\n",
    "        self.feature_extractor = nn.Sequential(*layers)\n",
    "        self.feature_extractor.eval()\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.fc = nn.Linear(in_features, 2)\n",
    "        self.optimizer = torch.optim.Adam\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_acc = Accuracy()\n",
    "        self.val_acc = Accuracy()\n",
    "        self.test_acc = Accuracy()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.fc(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.train_acc(y_pred, y)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_acc\", self.train_acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.val_acc(y_pred, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        y_pred = torch.softmax(y_hat, 1)\n",
    "        self.test_acc(y_pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", self.test_acc)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = self.optimizer(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Train the model and evaluate its performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"model\": CNNBaseline,\n",
    "    \"train\": True,              # if train = false, please specify a path to the model checkpoint\n",
    "    \"num_epochs\": 20,\n",
    "    \"lr\": 0.001,\n",
    "    \"checkpoint\": \"lightning_logs/baseline_with_augmentation/checkpoints/epoch=199-step=1400.ckpt\",\n",
    "    \"augment\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = [transforms.RandomHorizontalFlip(), transforms.RandomRotation(90)] if config[\"augment\"] else None\n",
    "dm = ImageDataModule(normalize=True, transform=transform)\n",
    "trainer = pl.Trainer(max_epochs=config[\"num_epochs\"], log_every_n_steps=5)\n",
    "dm.setup()\n",
    "if config[\"train\"]:\n",
    "    model = config[\"model\"](lr=config[\"lr\"])\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "else:\n",
    "    model = config[\"model\"].load_from_checkpoint(config[\"checkpoint\"])\n",
    "\n",
    "model.eval()\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Values\n",
    "Compute the shapley values and visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_shap(num_train: int):\n",
    "    \"\"\" Get the data used to compute shap values\n",
    "\n",
    "    Args:\n",
    "        (int) num_train: number of train samples\n",
    "        (int) num_test: number of test samples per class\n",
    "\n",
    "    Returns:\n",
    "        (Tensor, Tensor): train and test dataset\n",
    "    \"\"\"\n",
    "    dm_shap = ImageDataModule(batch_size=num_train)\n",
    "    dm_shap.setup()\n",
    "    train_batch = next(iter(dm_shap.train_dataloader()))\n",
    "    train_images, _ = train_batch\n",
    "\n",
    "    test_batch = next(iter(dm_shap.test_dataloader()))\n",
    "    test_images_raw, test_labels = test_batch\n",
    "    test_images_no = []\n",
    "    test_images_yes = []\n",
    "    for img, l in zip(test_images_raw, test_labels):\n",
    "        if l>0:\n",
    "            test_images_yes.append(img)\n",
    "        else:\n",
    "            test_images_no.append(img)\n",
    "    test_images_no = torch.stack(test_images_no, dim=0)\n",
    "    test_images_yes = torch.stack(test_images_yes, dim=0)\n",
    "    return train_images[:num_train], test_images_no, test_images_yes\n",
    "\n",
    "def normalize_images(imgs: torch.Tensor):\n",
    "    \"\"\" Normalize images\n",
    "    \"\"\"\n",
    "    return transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images, test_images_no, test_images_yes = get_dataset_shap(100)\n",
    "test_images = torch.cat([test_images_no[:1], test_images_yes[:1]], dim=0)\n",
    "\n",
    "e = shap.DeepExplainer(model, normalize_images(train_images))\n",
    "shap_values = e.shap_values(normalize_images(test_images))\n",
    "shap_numpy = [np.transpose(sv, (0,2,3,1)) for sv in shap_values]\n",
    "test_numpy = np.transpose(test_images.numpy(), (0,2,3,1))\n",
    "\n",
    "# plot the feature attributions\n",
    "shap.image_plot(shap_numpy, test_numpy)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "839a46e1465077c84b39be122588b4a3bd8a9d0460a9ee420f218244ce5714a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml4h')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
